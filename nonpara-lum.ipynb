{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1821eec7",
   "metadata": {},
   "source": [
    "# Modelling to Infer Void Parameters\n",
    "\n",
    "### Current features:\n",
    "- infers non-parametric luminsosity function\n",
    "    - build mock with sam non-parametric function, or with Schechter\n",
    "- building non-parametric density function\n",
    "    - currently sampling splines from uniform dist, then exponentiating to get $\\rho(r)$ points\n",
    "    - these points are then used to calculate shell masses which are then normalised\n",
    "    - it should be noted that currently the model only constrains the $\\rho(r)$ nodes up to a multiplicative constant, with rescaling happening manually\n",
    "- selection correction included, with fine integration grid\n",
    "    - introduce variable grid density to improve speed\n",
    "- infers latent params, mag and comoving dist, for each galaxy observed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09cdd162",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "from scipy import integrate, optimize\n",
    "import scipy as sp\n",
    "import numpyro\n",
    "import numpyro.distributions as dist\n",
    "from numpyro.infer.initialization import init_to_median, init_to_value\n",
    "from jax import random, jit\n",
    "from jax import numpy as jnp\n",
    "from jax import vmap\n",
    "from jaxopt import Bisection\n",
    "# import arviz as az\n",
    "from scipy.special import gammaincinv\n",
    "from jax.scipy.special import gamma, gammaincc, gammainc, gammaln\n",
    "from scipy.interpolate import interp1d\n",
    "import pickle\n",
    "import sys\n",
    "from jax import numpy as jnp\n",
    "from quadax import cumulative_simpson\n",
    "from jax.scipy.stats.norm import logcdf as norm_logcdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c53b372",
   "metadata": {},
   "source": [
    "### For use on cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8904dca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpi4py import MPI\n",
    "\n",
    "# Set up MPI\n",
    "comm = MPI.COMM_WORLD\n",
    "rank = comm.Get_rank()   # This process's ID\n",
    "size = comm.Get_size()   # Total processes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a8692e0",
   "metadata": {},
   "source": [
    "### Functions for non-parametric luminosity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f17801f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def int_linear(A, B, a, b):\n",
    "    # integral of (A + B x) dx\n",
    "    return A * (b - a) + B * (b**2 - a**2) / 2.0\n",
    "\n",
    "def compute_shell_masses_no_r2(x_nodes, edges, f_nodes):\n",
    "    \"\"\"\n",
    "    Like compute_shell_masses(), but integrates just f(x).\n",
    "    Useful for a non-parametric luminosity function p(M) with piecewise-linear φ(M).\n",
    "    \"\"\"\n",
    "    n_shells = edges.shape[0] - 1\n",
    "    n_nodes  = x_nodes.shape[0]\n",
    "    M = jnp.zeros((n_shells, n_nodes))\n",
    "\n",
    "    for i in range(n_shells):\n",
    "        a, b = edges[i], edges[i+1]\n",
    "\n",
    "        for j in range(n_nodes):\n",
    "            # left half of linear hat\n",
    "            if j > 0:\n",
    "                s0, s1 = x_nodes[j-1], x_nodes[j]\n",
    "                lo = jnp.maximum(a, s0)\n",
    "                hi = jnp.minimum(b, s1)\n",
    "                cond = hi > lo\n",
    "                denom = s1 - s0 + 1e-12\n",
    "                A = -s0 / denom\n",
    "                B = 1.0 / denom\n",
    "                M = M.at[i, j].set(M[i, j] + jnp.where(cond, int_linear(A, B, lo, hi), 0.0))\n",
    "\n",
    "            # right half of linear hat\n",
    "            if j < n_nodes - 1:\n",
    "                s0, s1 = x_nodes[j], x_nodes[j+1]\n",
    "                lo = jnp.maximum(a, s0)\n",
    "                hi = jnp.minimum(b, s1)\n",
    "                cond = hi > lo\n",
    "                denom = s1 - s0 + 1e-12\n",
    "                A = s1 / denom\n",
    "                B = -1.0 / denom\n",
    "                M = M.at[i, j].set(M[i, j] + jnp.where(cond, int_linear(A, B, lo, hi), 0.0))\n",
    "\n",
    "    shell_masses = M @ f_nodes\n",
    "    return shell_masses\n",
    "\n",
    "\n",
    "def build_pdf_cdf_no_r2(x_nodes, edges, f_nodes, x_grid):\n",
    "    shell_masses = compute_shell_masses_no_r2(x_nodes, edges, f_nodes)\n",
    "    total_mass = jnp.sum(shell_masses)\n",
    "    shell_mass_norm = shell_masses / total_mass\n",
    "\n",
    "    f_grid = jnp.interp(x_grid, x_nodes, f_nodes)\n",
    "    pdf_grid = f_grid / total_mass\n",
    "\n",
    "    dx = x_grid[1] - x_grid[0]\n",
    "    cdf_grid = jnp.cumsum(pdf_grid) * dx\n",
    "    cdf_grid = cdf_grid / cdf_grid[-1]\n",
    "\n",
    "    return pdf_grid, cdf_grid, shell_mass_norm, f_grid, total_mass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85bf0cef",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0fe342",
   "metadata": {},
   "outputs": [],
   "source": [
    "# comoving distance from redshift\n",
    "def redshift_to_dist(z, c, omega_m):\n",
    "    \n",
    "    \"\"\"\n",
    "    Takes inputs: redshift, c, H0, and matter density param\n",
    "    Outputs: comoving distance\n",
    "    \"\"\"\n",
    "    \n",
    "    return (c / 100) * (z - 0.75 * omega_m * z**2)\n",
    "\n",
    "\n",
    "# redshift from comoving distance\n",
    "def dc_to_redshift(D_c, c, omega_m):\n",
    "    \n",
    "    \"\"\"\n",
    "    Takes inputs: comoving distance (in Mpc/h), c, and matter density param\n",
    "    Outputs: redshift\n",
    "    \"\"\"\n",
    "    \n",
    "    D = (D_c * 100) / c\n",
    "    return (1 - jnp.sqrt(1 - 3 * omega_m * D)) / (1.5 * omega_m)\n",
    "\n",
    "\n",
    "# interpolation for non-parametric functions\n",
    "def f_of_r(r, f_pts):\n",
    "    \"\"\"\n",
    "    Interpolates f(r) for given spline points (f_pts)\n",
    "    \"\"\"\n",
    "            \n",
    "    # clip r to ensure within min/max of r_points\n",
    "    r_clipped = jnp.clip(r, r_points[0], r_points[-1])\n",
    "    return jnp.interp(r_clipped, r_points, f_pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be9cda32",
   "metadata": {},
   "source": [
    "### Selection correction functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da2d4fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dc2mu(dc):\n",
    "    \"\"\"Convert distance in Mpc to distance modulus.\"\"\"\n",
    "    z = dc_to_redshift(dc, c, omega_m)\n",
    "    return 5 * jnp.log10(dc * (1 + z)) + 25\n",
    "\n",
    "def mu2r(mu):\n",
    "    \"\"\"Convert distance modulus to distance in Mpc.\"\"\"\n",
    "    return 10 ** ((mu - 25) / 5)\n",
    "\n",
    "\n",
    "def simpson2d(f_val, x_grid, y_grid):\n",
    "    \"\"\"Evaluate a 2D integral using Simpson's rule.\"\"\"\n",
    "    inner = cumulative_simpson(f_val, x=y_grid, axis=1, initial=0.0)\n",
    "    outer = cumulative_simpson(inner, x=x_grid, axis=0, initial=0.0)\n",
    "    return outer[-1, -1]\n",
    "\n",
    "\n",
    "# def log_pdf_LF(M, alpha, M_star, M_abs_Sun):\n",
    "#     \"\"\"Simple Gaussian-like luminosity function. Replace with Schechter or other.\"\"\"\n",
    "#     norm = gamma(1 - alpha) * jnp.exp(-0.4*jnp.log(10)*(M_star - M_abs_Sun))\n",
    "#     Ln_L_by_Lstar = -0.4*jnp.log(10)*(M - M_star)\n",
    "#     log_pdf_L = -alpha * Ln_L_by_Lstar - jnp.exp(Ln_L_by_Lstar) - jnp.log(norm) #Wrt L\n",
    "#     log_pdf_M = log_pdf_L + jnp.log(0.4*jnp.log(10)) - 0.4*jnp.log(10)*(M - M_abs_Sun) #Wrt M\n",
    "#     return log_pdf_M\n",
    "\n",
    "\n",
    "\n",
    "def log_integrand_p_det(M, dc, M_star, alpha, r_vals, pdf_vals, mlim, m_err, M_abs_Sun, log_norm_L):\n",
    "    \"\"\"Logarithmic integrand for the detection probability.\"\"\"\n",
    "    \n",
    "    app_mag = M + dc2mu(dc)\n",
    "    x = (mlim - app_mag) / m_err\n",
    "    \n",
    "    #Radial distribution.\n",
    "    \n",
    "    inv_pdf = jnp.interp(dc, r_vals, pdf_vals)\n",
    "    \n",
    "    ln_prior_dc = jnp.log(inv_pdf)\n",
    "    \n",
    "    return norm_logcdf(x) + ln_prior_dc + log_pdf_LF_trunc(M, alpha, M_star, M_abs_Sun, log_norm_L)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5612ed4d",
   "metadata": {},
   "source": [
    "### Functions for non-parametric density\n",
    "\n",
    "Same structure as for luminosity function, but with additional $r^2$ factor to account for volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf33b421",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# Analytic integral of r^2 * linear function\n",
    "# -------------------------\n",
    "def int_r2_linear(A, B, a, b):\n",
    "    # integral of r^2 * (A + B r) dr\n",
    "    return A * (b**3 - a**3) / 3.0 + B * (b**4 - a**4) / 4.0\n",
    "\n",
    "# -------------------------\n",
    "# Compute mass integral over each shell from node values\n",
    "# -------------------------\n",
    "def compute_shell_masses(r_nodes, edges, rho_nodes):\n",
    "    n_shells = edges.shape[0] - 1\n",
    "    n_nodes = r_nodes.shape[0]\n",
    "    M = jnp.zeros((n_shells, n_nodes))\n",
    "\n",
    "    for i in range(n_shells):\n",
    "        a, b = edges[i], edges[i + 1]\n",
    "\n",
    "        for j in range(n_nodes):\n",
    "            # left half of linear hat\n",
    "            if j > 0:\n",
    "                s0, s1 = r_nodes[j-1], r_nodes[j]\n",
    "                lo = jnp.maximum(a, s0)\n",
    "                hi = jnp.minimum(b, s1)\n",
    "                cond = hi > lo\n",
    "                denom = s1 - s0 + 1e-12\n",
    "                A = -s0 / denom\n",
    "                B = 1.0 / denom\n",
    "                M = M.at[i,j].set(M[i,j] + jnp.where(cond, int_r2_linear(A, B, lo, hi), 0.0))\n",
    "\n",
    "            # right half of linear hat\n",
    "            if j < n_nodes - 1:\n",
    "                s0, s1 = r_nodes[j], r_nodes[j+1]\n",
    "                lo = jnp.maximum(a, s0)\n",
    "                hi = jnp.minimum(b, s1)\n",
    "                cond = hi > lo\n",
    "                denom = s1 - s0 + 1e-12\n",
    "                A = s1 / denom\n",
    "                B = -1.0 / denom\n",
    "                M = M.at[i,j].set(M[i,j] + jnp.where(cond, int_r2_linear(A, B, lo, hi), 0.0))\n",
    "\n",
    "    # compute shell masses\n",
    "    shell_masses = M @ rho_nodes\n",
    "    return shell_masses\n",
    "\n",
    "# -------------------------\n",
    "# Build normalized PDF and CDF on grid\n",
    "# -------------------------\n",
    "def build_pdf_cdf(r_nodes, edges, rho_nodes, r_grid):\n",
    "    # compute shell masses for exact normalization\n",
    "    shell_masses = compute_shell_masses(r_nodes, edges, rho_nodes)\n",
    "    total_mass = jnp.sum(shell_masses)\n",
    "    shell_mass_norm = shell_masses / total_mass\n",
    "\n",
    "    # linear interpolation of rho\n",
    "    rho_grid = jnp.interp(r_grid, r_nodes, rho_nodes)\n",
    "\n",
    "    # PDF = r^2 * rho(r) / total_mass\n",
    "    pdf_grid = r_grid**2 * rho_grid / total_mass\n",
    "    # print('pdf norm', jnp.trapezoid(pdf_grid, r_grid))\n",
    "\n",
    "    # CDF via cumulative trapezoid\n",
    "    dr = r_grid[1] - r_grid[0]\n",
    "    cdf_grid = jnp.cumsum(pdf_grid) * dr\n",
    "    # print('cdf final val = ', cdf_grid[-1])\n",
    "    cdf_grid = cdf_grid / cdf_grid[-1]\n",
    "\n",
    "    return pdf_grid, cdf_grid, shell_mass_norm, rho_grid, total_mass\n",
    "\n",
    "# -------------------------\n",
    "# Inverse CDF sampling\n",
    "# -------------------------\n",
    "def inv_cdf_sample(r_grid, cdf_grid, u):\n",
    "    \"\"\"\n",
    "    u: uniform random values [0,1]\n",
    "    returns r samples\n",
    "    \"\"\"\n",
    "    return jnp.interp(u, cdf_grid, r_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ae0480",
   "metadata": {},
   "source": [
    "### Model for HMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af2b085",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(app_mag_obs, m_err, z_obs, z_err):\n",
    "    \n",
    "\n",
    "    # Priors\n",
    "    dc_max_MCMC = dc_max_ground\n",
    "    alpha = numpyro.sample(\"alpha\", dist.Uniform(.5, 1.2))\n",
    "    M_star = numpyro.sample(\"M_star\", dist.Uniform(-23.0, -21.0))\n",
    "    # concentration = jnp.ones(n_splines)\n",
    "    # shell_mass = numpyro.sample(\"shell_mass\", dist.Dirichlet(concentration))\n",
    "    \n",
    "    # # convert sampled shell masses to rho(r) spline points\n",
    "    # rho_pts = shell_mass / shell_weights\n",
    "    # numpyro.deterministic(\"f_pts\", rho_pts)\n",
    "\n",
    "    M_abs_Sun = M_abs_Sun_ground\n",
    "\n",
    "    log_norm_L = schechter_log_norm_L(alpha, M_star, M_abs_Sun)\n",
    "\n",
    "    sigma_f = 1.0   # std dev on log(rho)\n",
    "\n",
    "    # log rho at spline knots\n",
    "    f = numpyro.sample(\"f_pts\", dist.Normal(0.0, sigma_f).expand([n_splines]))\n",
    "\n",
    "    rho_pts = jnp.exp(f)\n",
    "    \n",
    "    # computing volume pdf for sampled spline points\n",
    "    r_vals = jnp.linspace(0, dc_max_ground, 10000)\n",
    "    \n",
    "    pdf_grid, cdf_grid, shell_mass, rho_grid, total_mass = build_pdf_cdf(r_points, edges, rho_pts, r_vals)\n",
    "\n",
    "    \n",
    "    numpyro.deterministic(\"rho_pts\", rho_pts)\n",
    "    numpyro.deterministic(\"shell_mass\", shell_mass)\n",
    "\n",
    "    \n",
    "    # calculating phi_star for each point in chain\n",
    "    phi_star = N_obs / (gamma(1 - alpha) * abs(M_star))\n",
    "    numpyro.deterministic(\"phi_star\", phi_star)\n",
    "    \n",
    "    # mag selection correction\n",
    "    #M_star = M_abs_Sun - 2.5*jnp.log10(L_star)\n",
    "    M_min = M_BRIGHT\n",
    "    M_max = M_FAINT\n",
    "    M_grid = jnp.linspace(M_min, M_max, 1001)\n",
    "\n",
    "\n",
    "    dc_min = 1e-5\n",
    "    dc_max = dc_max_MCMC\n",
    "\n",
    "    dc_grid = jnp.linspace(dc_min, dc_max, 1001)\n",
    "\n",
    "    mlim = 18\n",
    "    m_err = 0.05\n",
    "    \n",
    "    X, Y = jnp.meshgrid(M_grid, dc_grid, indexing='ij')\n",
    "    log_integrand = log_integrand_p_det(X, Y, M_star, alpha, r_vals, pdf_grid, mlim, m_err, M_abs_Sun, log_norm_L)\n",
    "\n",
    "\n",
    "    # This is p(S = 1 | Lambda) from the Overleaf notation.\n",
    "    p_det = simpson2d(jnp.exp(log_integrand), M_grid, dc_grid)\n",
    "    numpyro.factor(\"selection_effect\", -N_obs * jnp.log(p_det))\n",
    "\n",
    "    \n",
    "    # plate over galaxies\n",
    "    with numpyro.plate(\"data\", N_obs):\n",
    "        \n",
    "        # sample absolute magnitude and comoving distance\n",
    "        M_true = numpyro.sample(\"M_true\", dist.Uniform(M_BRIGHT, M_FAINT))\n",
    "        d_c_true = numpyro.sample(\"d_c_true\", dist.Uniform(0, dc_max_MCMC))\n",
    "        \n",
    "\n",
    "        # apply volume prior\n",
    "        inv_pdf = jnp.interp(d_c_true, r_vals, pdf_grid)\n",
    "        log_prior = jnp.log(inv_pdf)\n",
    "        \n",
    "        numpyro.factor(\"volume_prior\", log_prior)\n",
    "        \n",
    "        # compute redshift from comoving dist\n",
    "        z_true = dc_to_redshift(d_c_true, c, omega_m)\n",
    "        \n",
    "        # likelihood term for redshift\n",
    "        numpyro.sample(\"z_likelihood\", dist.Normal(z_true, z_err), obs=z_obs)\n",
    "        \n",
    "        # compute luminosity distance\n",
    "        d_L = (1 + z_true) * d_c_true\n",
    "        \n",
    "        # predict app mag from abs mag and lum dist\n",
    "        m_model = M_true + 5 * jnp.log10(d_L) + 25 # magnitude in units related to h\n",
    "        \n",
    "        \n",
    "        # apply Schechter prior on M_true\n",
    "        numpyro.factor(\"M_true_prior\", log_pdf_LF_trunc(M_true, alpha, M_star, M_abs_Sun, log_norm_L))\n",
    "        \n",
    "        # likelihood term for apparent magnitude\n",
    "        numpyro.sample(\"m_obs\", dist.Normal(m_model, m_err), obs=app_mag_obs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c501b4",
   "metadata": {},
   "source": [
    "### MPI setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9f4bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_runs = 1\n",
    "alpha_results = []\n",
    "L_star_results = []\n",
    "phi_star_results = []\n",
    "rho_pts_results = []\n",
    "shell_m_results = []\n",
    "\n",
    "alpha_truths = []\n",
    "M_star_truths = []\n",
    "rho_pts_truths = []\n",
    "shell_m_truths =[]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce077e5",
   "metadata": {},
   "source": [
    "### Mock generation and sampling\n",
    "\n",
    "- Loop for purpose of MPI\n",
    "- MPI data storage at end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7147a3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(N_runs):\n",
    "    \n",
    "    # print(f\"Rank {rank}: Starting run \", i+1, \" of \", N_runs)\n",
    "    \n",
    "    \n",
    "    try:\n",
    "\n",
    "        # np.random.seed((rank * N_runs) + i)\n",
    "        np.random.seed(0)\n",
    "\n",
    "\n",
    "        # set params\n",
    "        alpha = np.random.uniform(.5, 1.2)\n",
    "        L_star = 10**np.random.uniform(6, 6.8)\n",
    "        N_tot = 3000000\n",
    "        N_obs_target = 40000\n",
    "        dc_max_ground = 2000\n",
    "        dc_max_inv_ground = 1.0/dc_max_ground\n",
    "        omega_m = 0.3\n",
    "        c = 2.998 * 10**5\n",
    "        H_0 = 70\n",
    "        h = H_0 / 100\n",
    "        \n",
    "        M_abs_Sun_ground = -6.0 #Look up for relevant filter from Willmer_2018 (ApJS, 236, 47) or similar\n",
    "        M_L_ratio = 1.0 #Ask about appropriate value.\n",
    "        \n",
    "        m_err, z_err = .05, .001\n",
    "        mlim = 18\n",
    "        \n",
    "        \n",
    "\n",
    "        ## sampling spline points and generating non-parametric density function\n",
    "        n_splines = 11\n",
    "        \n",
    "        r_points = np.linspace(0, dc_max_ground, n_splines)\n",
    "        \n",
    "        r_vals = np.linspace(0, dc_max_ground, 10000)\n",
    "\n",
    "        \n",
    "        ## Dirichlet sampling on r^2*rho(r)\n",
    "        \n",
    "        # shell edges from spline knots\n",
    "        edges = np.empty(n_splines + 1)\n",
    "        edges[0] = 0.5 * r_points[0]\n",
    "        edges[1:-1] = 0.5 * (r_points[:-1] + r_points[1:])\n",
    "        edges[-1] = dc_max_ground\n",
    "\n",
    "\n",
    "        sigma_f_ground = 1.0\n",
    "\n",
    "        # draw log(rho) splines\n",
    "        f_ground = np.random.uniform(-3.0, 3.0, size=n_splines)\n",
    "        rho_pts_ground = jnp.exp(f_ground)\n",
    "\n",
    "        pdf_grid, cdf_grid, shell_mass_ground, rho_grid_ground, total_mass_ground = build_pdf_cdf(r_points, edges, rho_pts_ground, r_vals)\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "        # # shell weights integrating r^2 dr\n",
    "        # shell_weights = (edges[1:]**3 - edges[:-1]**3) / 3.0\n",
    "        \n",
    "        # # Dirichlet over shell 'masses'\n",
    "        # # changing alpha0 leads to smoother/spikier sampling\n",
    "        # alpha0_true = 1.0\n",
    "        # shell_mass_ground = np.random.dirichlet(alpha0_true * np.ones(n_splines))\n",
    "        \n",
    "        \n",
    "        # # convert shell masses to rho(r) at splines\n",
    "        # rho_pts_ground = shell_mass_ground / shell_weights\n",
    "        \n",
    "        \n",
    "        # print(\"sum(shell_mass_ground) =\", shell_mass_ground.sum())\n",
    "        # print(\"sum(rho_pts_ground * shell_weights) =\", np.sum(rho_pts_ground * shell_weights))\n",
    "\n",
    "    \n",
    "        # f_vals_ground = f_of_r(r_vals, rho_pts_ground)\n",
    "        # pdf_vals_ground = r_vals**2 * f_vals_ground\n",
    "        \n",
    "        # norm_grid = jnp.trapezoid(pdf_vals_ground, r_vals)\n",
    "        # print(\"grid norm before renorm:\", norm_grid)\n",
    "        \n",
    "        # pdf_vals_ground /= norm_grid\n",
    "        \n",
    "        # # build cdf\n",
    "        # dr = r_vals[1] - r_vals[0]\n",
    "        # cdf_vals_ground = np.cumsum(pdf_vals_ground) * dr\n",
    "        # print(\"cdf end =\", cdf_vals_ground[-1])\n",
    "        # cdf_vals_ground /= cdf_vals_ground[-1]\n",
    "\n",
    "        \n",
    "        # inv cdf\n",
    "        inv_cdf = interp1d(cdf_grid, r_vals)\n",
    "    \n",
    "        \n",
    "        # # dist sampling testing\n",
    "        \n",
    "        # u_dist_test = np.random.rand(10000)\n",
    "        # generated_dist = inv_cdf(u_dist_test)\n",
    "        \n",
    "        # import seaborn as sns\n",
    "        # import matplotlib.pyplot as plt \n",
    "        # sns.histplot(generated_dist, stat='density')\n",
    "        # plt.plot(r_vals, pdf_vals)\n",
    "        # plt.show()\n",
    "        # plt.clf()\n",
    "        \n",
    "        # plt.scatter(r_points, f_pts)\n",
    "        # plt.show()\n",
    "        \n",
    "        # plt.plot(r_vals, f_vals)\n",
    "        # plt.yscale('log')\n",
    "        # plt.show()\n",
    "\n",
    "        schechter_cdf_inv = schechter_inv_cdf_trunc(alpha, L_star, M_abs_Sun_ground)\n",
    "        \n",
    "        ###############################  \n",
    "        \n",
    "        ## rejection sampling\n",
    "        target_N_obs = N_obs_target\n",
    "        accepted_ms = []\n",
    "        accepted_zs = []\n",
    "        accepted_Ms = []\n",
    "        accepted_dcs = []\n",
    "\n",
    "        # draw in batches until enough accepted\n",
    "        while len(accepted_ms) < target_N_obs:\n",
    "            # choose batch size adaptively: 20x remaining, min 1000 for efficiency\n",
    "            remaining = target_N_obs - len(accepted_ms)\n",
    "            batch = max(5000, remaining * 2000)\n",
    "            \n",
    "            # rands for sampling\n",
    "            u_dist = np.random.rand(batch)\n",
    "            u_lum = np.random.rand(batch)\n",
    "            \n",
    "            # candidate distances and lums\n",
    "            # to then be converted to observed values\n",
    "            d_c_cand = inv_cdf(u_dist)\n",
    "            L_cand = schechter_cdf_inv(u_lum)\n",
    "            M_cand = M_abs_Sun_ground - 2.5 * np.log10(L_cand) + 2.5 * np.log10(M_L_ratio)\n",
    "            z_cand = dc_to_redshift(d_c_cand, c, omega_m)\n",
    "            d_L_cand = (1.0 + z_cand) * d_c_cand\n",
    "            mu_cand = 5.0 * np.log10(d_L_cand) + 25.0\n",
    "            m_cand = M_cand + mu_cand\n",
    "            \n",
    "            # add scatter to observed vals and apply selection\n",
    "            z_mock = np.random.normal(z_cand, z_err, size=batch)\n",
    "            m_mock = np.random.normal(m_cand, m_err, size=batch)\n",
    "            sel = m_mock < mlim\n",
    "            \n",
    "            \n",
    "            if np.any(sel):\n",
    "                accepted_ms.extend(list(m_mock[sel]))\n",
    "                accepted_zs.extend(list(z_mock[sel]))\n",
    "                accepted_Ms.extend(list(M_cand[sel]))\n",
    "                accepted_dcs.extend(list(d_c_cand[sel]))\n",
    "        # truncate to exactly target_N_obs\n",
    "        accepted_ms = np.array(accepted_ms[:target_N_obs])\n",
    "        accepted_zs = np.array(accepted_zs[:target_N_obs])\n",
    "        accepted_Ms = np.array(accepted_Ms[:target_N_obs])\n",
    "        accepted_dcs = np.array(accepted_dcs[:target_N_obs])\n",
    "        \n",
    "        m_obs = accepted_ms\n",
    "        z_obs = accepted_zs\n",
    "        N_obs = target_N_obs\n",
    "        M_ground = accepted_Ms\n",
    "        d_c_ground = accepted_dcs\n",
    "        \n",
    "        \n",
    "        M_star = M_abs_Sun_ground - 2.5*jnp.log10(L_star)\n",
    "        \n",
    "        \n",
    "        phi_star = N_obs/(gamma(1 - alpha) * abs(M_star))\n",
    "            \n",
    "        \n",
    "        \n",
    "        ## Run MCMC\n",
    "        rng_key = random.PRNGKey(0)\n",
    "        rng_key, rng_key_ = random.split(rng_key)\n",
    "        kernel = numpyro.infer.NUTS(model, init_strategy=init_to_median(num_samples=1000))\n",
    "        # kernel = numpyro.infer.NUTS(model)\n",
    "        mcmc = numpyro.infer.MCMC(kernel, num_warmup=250, num_samples=1001)\n",
    "        mcmc.run(rng_key_, app_mag_obs=m_obs, m_err=m_err, z_obs=z_obs, z_err=z_err)\n",
    "        \n",
    "        # mcmc.print_summary()\n",
    "        samples = mcmc.get_samples()\n",
    "        # res = az.from_numpyro(mcmc)\n",
    "        \n",
    "        \n",
    "        \n",
    "        # filename = f\"../HMC_output/mag_selection/samples_rank_{rank}_run_{i}.pkl\"\n",
    "        # with open(filename, 'wb') as f:\n",
    "        #     pickle.dump(samples, f)\n",
    "            \n",
    "        #print(f'Rank {rank}, run {i} saved results to {filename}')\n",
    "        \n",
    "        \n",
    "        \n",
    "        alpha_samples = np.array(samples['alpha'])\n",
    "        L_star_samples = np.array(samples['M_star'])\n",
    "        phi_star_samples = np.array(samples['phi_star'])\n",
    "        rho_pts_samples = np.array(samples['rho_pts'])\n",
    "        shell_m_samples = np.array(samples['shell_mass'])\n",
    "\n",
    "        shell_sum = np.sum(shell_m_samples, axis=0)\n",
    "        \n",
    "        \n",
    "        alpha_results.append(alpha_samples)\n",
    "        L_star_results.append(L_star_samples)\n",
    "        phi_star_results.append(phi_star_samples)\n",
    "        rho_pts_results.append(rho_pts_samples)\n",
    "        shell_m_results.append(shell_m_samples)\n",
    "        \n",
    "        alpha_truths.append(alpha)\n",
    "        M_star_truths.append(M_star)\n",
    "        rho_pts_truths.append(rho_pts_ground)\n",
    "        shell_m_truths.append(shell_mass_ground)\n",
    "\n",
    "\n",
    "    except Exception as e:\n",
    "        # print(f\"Rank {rank}, run {i} failed: {e}\")\n",
    "        \n",
    "        continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c92adc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "shell_sum = np.sum(shell_m_samples, axis=1)\n",
    "print(shell_sum)\n",
    "rho_sum = np.sum(rho_pts_samples, axis=1)\n",
    "print(rho_sum)\n",
    "print(np.sum(rho_pts_ground))\n",
    "print(build_pdf_cdf(r_points, edges, rho_pts_ground, r_vals)[-1])\n",
    "mcmc.print_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac19076b",
   "metadata": {},
   "source": [
    "### MPI data collection and saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85abe02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only build arrays if we have data\n",
    "if alpha_results:\n",
    "    alpha_samples = np.array(alpha_results).T\n",
    "    L_star_samples = np.array(L_star_results).T\n",
    "    phi_star_samples = np.array(phi_star_results).T\n",
    "    rho_pts_samples = np.array(rho_pts_results)\n",
    "    shell_m_samples = np.array(shell_m_results)\n",
    "else:\n",
    "    alpha_samples = None\n",
    "    L_star_samples = None\n",
    "    phi_star_samples = None\n",
    "    rho_pts_samples = None\n",
    "    shell_m_samples = None\n",
    "\n",
    "\n",
    "\n",
    "all_alpha = comm.gather(alpha_samples, root=0)\n",
    "all_L_star = comm.gather(L_star_samples, root=0)\n",
    "all_phi_star = comm.gather(phi_star_samples, root=0)\n",
    "all_rho_pts = comm.gather(rho_pts_samples, root=0)\n",
    "all_shell_m = comm.gather(shell_m_samples, root=0)\n",
    "\n",
    "\n",
    "alpha_truth = comm.gather(alpha_truths, root=0)\n",
    "M_star_truth = comm.gather(M_star_truths, root=0)\n",
    "rho_pts_truth = comm.gather(rho_pts_truths, root=0)\n",
    "shell_m_truth = comm.gather(shell_m_truths, root=0)\n",
    "\n",
    "\n",
    "master_results = {}\n",
    "\n",
    "if rank == 0:\n",
    "    \n",
    "    # all_alpha to np.array\n",
    "    \n",
    "    master_results = {'alpha': {}, 'M_star': {}, 'phi_star': {}, 'rho_pts': {}, 'shell_mass':{},\n",
    "                      'alpha_truth': {}, 'M_star_truth': {}, 'rho_pts_truth': {}, 'shell_mass_truth':{}}\n",
    "    for i in range(size):\n",
    "        if all_alpha[i] is None:\n",
    "            print(f\"Skipping rank {rank} (no valid results)\")\n",
    "            continue\n",
    "        \n",
    "        master_results['alpha'][i] = all_alpha[i]\n",
    "        master_results['M_star'][i] = all_L_star[i]\n",
    "        master_results['phi_star'][i] = all_phi_star[i]\n",
    "        master_results['rho_pts'][i] = all_rho_pts[i]\n",
    "        master_results['shell_mass'][i] = all_shell_m[i]\n",
    "        \n",
    "        master_results['alpha_truth'][i] = alpha_truth[i]\n",
    "        master_results['M_star_truth'][i] = M_star_truth[i]\n",
    "        master_results['rho_pts_truth'][i] = rho_pts_truth[i]\n",
    "        master_results['shell_mass_truth'][i] = shell_m_truth[i]\n",
    "\n",
    "    with open(\"../HMC_output/mag_selection/rand_truths_nonpara_100trial_40kgals.pkl\", \"wb\") as f:\n",
    "        pickle.dump(master_results, f)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df2a40e",
   "metadata": {},
   "source": [
    "### Plotting for a single run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0937f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import corner\n",
    "import arviz as az\n",
    "import seaborn as sns\n",
    "\n",
    "res = az.from_numpyro(mcmc)\n",
    "\n",
    "\n",
    "## corner with alpha, M* and some rho_pts\n",
    "posterior = res.posterior\n",
    "\n",
    "# Get shapes\n",
    "# alpha: (chain, draw)\n",
    "alpha_samps = posterior['alpha'].values.reshape(-1)        # (n_samples,)\n",
    "M_star_samps = posterior['M_star'].values.reshape(-1)      # (n_samples,)\n",
    "\n",
    "\n",
    "# rho_pts: (chain, draw, n_knots)\n",
    "rho_samps = posterior['rho_pts'].values                     # (chain, draw, n_knots)\n",
    "rho_samps_flat = rho_samps.reshape(-1, rho_samps.shape[-1])      # (n_samples, n_knots)\n",
    "\n",
    "\n",
    "# renormalising rho values - set rho0 to truth and scale remaining nodes by same factor\n",
    "scaling = rho_pts_truths[0][0] / jnp.mean(rho_samps_flat[:, 0])\n",
    "\n",
    "rho_samps_scaled = rho_samps_flat * scaling\n",
    "\n",
    "# Pick first 3 knots, for example\n",
    "rho0 = rho_samps_scaled[:, 0]\n",
    "rho1 = rho_samps_scaled[:, 1]\n",
    "rho2 = rho_samps_scaled[:, 2]\n",
    "\n",
    "# Stack into a single samples array for corner: (n_samples, n_params)\n",
    "subset = np.column_stack([alpha_samps, M_star_samps, rho0, rho1, rho2])\n",
    "\n",
    "labels = [r\"$\\alpha$\", r\"$M_\\star$\", r\"$\\rho_0$\", r\"$\\rho_1$\", r\"$\\rho_2$\"]\n",
    "\n",
    "fig = corner.corner(\n",
    "    subset,\n",
    "    labels=labels,\n",
    "    show_titles=True,\n",
    "    truths=[alpha, M_star, rho_pts_ground[0], rho_pts_ground[1], rho_pts_ground[2]],\n",
    ")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## corner with all f_pts\n",
    "# extract f_pts: shape (chain, draw, n_knots)\n",
    "rho_da = res.posterior[\"rho_pts\"]        # xarray DataArray\n",
    "rho_vals_corner = rho_da.values * scaling     # numpy array\n",
    "\n",
    "\n",
    "# flatten chains and draws → (n_samples, n_knots)\n",
    "n_chains, n_draws, n_knots = rho_vals_corner.shape\n",
    "rho_flat = rho_vals_corner.reshape(n_chains * n_draws, n_knots)\n",
    "corner_data = np.column_stack([alpha_samps, M_star_samps, rho_flat])\n",
    "\n",
    "\n",
    "# nice labels: f_0, f_1, ..., f_{n_knots-1}\n",
    "labels = [r\"$\\alpha$\", r\"$M_\\star$\"] + [fr\"$\\rho_{{{i}}}$\" for i in range(n_splines)]\n",
    "alpha_arr = np.atleast_1d(float(alpha))\n",
    "M_star_arr = np.asarray(M_star).ravel()\n",
    "rho_arr = np.asarray(rho_pts_ground).ravel()\n",
    "truths = np.concatenate([alpha_arr, M_star_arr, rho_arr])\n",
    "\n",
    "fig = corner.corner(\n",
    "    corner_data,\n",
    "    labels=labels,\n",
    "    show_titles=True,\n",
    "    truths=truths\n",
    ")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "## corner with all shell mass\n",
    "# extract shell mass: shape (chain, draw, n_knots)\n",
    "sm_da = res.posterior[\"shell_mass\"]        # xarray DataArray\n",
    "sm_vals_corner = sm_da.values                    # numpy array\n",
    "\n",
    "# flatten chains and draws → (n_samples, n_knots)\n",
    "n_chains, n_draws, n_knots = sm_vals_corner.shape\n",
    "sm_flat = sm_vals_corner.reshape(n_chains * n_draws, n_knots)\n",
    "corner_data = np.column_stack([alpha_samps, M_star_samps, sm_flat])\n",
    "\n",
    "\n",
    "# nice labels: f_0, f_1, ..., f_{n_knots-1}\n",
    "labels = [r\"$\\alpha$\", r\"$M_\\star$\"] + [fr\"$sm_{{{i}}}$\" for i in range(n_splines)]\n",
    "alpha_arr = np.atleast_1d(float(alpha))\n",
    "M_star_arr = np.asarray(M_star).ravel()\n",
    "sm_arr = np.asarray(shell_mass_ground).ravel()\n",
    "truths = np.concatenate([alpha_arr, M_star_arr, sm_arr])\n",
    "\n",
    "fig = corner.corner(\n",
    "    corner_data,\n",
    "    labels=labels,\n",
    "    show_titles=True,\n",
    "    truths=truths\n",
    "    )\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "M_samples = posterior['M_true'].values\n",
    "M_mean = M_samples.mean(axis=(0,1))\n",
    "\n",
    "M_lower = np.percentile(M_samples, 16, axis=(0, 1))\n",
    "M_upper = np.percentile(M_samples, 84, axis=(0, 1))\n",
    "\n",
    "plt.scatter(M_ground, M_mean, s=3, alpha=0.5, label='Galaxies')\n",
    "\n",
    "plt.errorbar(M_ground, M_mean,\n",
    "             yerr=[M_mean - M_lower, M_upper - M_mean],\n",
    "             fmt=\"none\", ecolor=\"gray\", alpha=0.1)\n",
    "\n",
    "mn = min(M_ground.min(), M_mean.min())\n",
    "mx = max(M_ground.max(), M_mean.max())\n",
    "plt.plot([mn, mx], [mn, mx], linestyle=\"--\", linewidth=1, color=\"k\", label=\"1:1\")\n",
    "\n",
    "plt.xlabel(r\"True M\")\n",
    "plt.ylabel(r\"Posterior mean $M_{\\mathrm{true}}$\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "dc_samples = posterior['d_c_true'].values\n",
    "dc_mean = dc_samples.mean(axis=(0,1))\n",
    "\n",
    "dc_lower = np.percentile(dc_samples, 16, axis=(0, 1))\n",
    "dc_upper = np.percentile(dc_samples, 84, axis=(0, 1))\n",
    "\n",
    "plt.scatter(d_c_ground, dc_mean, s=3, alpha=0.5, label='Galaxies')\n",
    "\n",
    "plt.errorbar(d_c_ground, dc_mean,\n",
    "             yerr=[dc_mean - dc_lower, dc_upper - dc_mean],\n",
    "             fmt=\"none\", ecolor=\"gray\", alpha=0.1)\n",
    "\n",
    "mn = min(d_c_ground.min(), dc_mean.min())\n",
    "mx = max(d_c_ground.max(), dc_mean.max())\n",
    "plt.plot([mn, mx], [mn, mx], linestyle=\"--\", linewidth=1, color=\"k\", label=\"1:1\")\n",
    "\n",
    "plt.xlabel(r\"True $D_c$\")\n",
    "plt.ylabel(r\"Posterior mean $D_c$\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# plt.plot(r_points, rho_pts_ground)\n",
    "# plt.plot(r_points, np.mean(f_flat, axis=0))\n",
    "# plt.yscale('log')\n",
    "# plt.show()\n",
    "\n",
    "# f_vals_mcmc = f_of_r(r_vals, np.mean(f_samps_flat, axis=0))\n",
    "\n",
    "# plt.plot(r_vals, f_vals_ground, label='True rho(r)')\n",
    "# plt.plot(r_vals, f_vals_mcmc, label='Sampled rho(r)')\n",
    "# plt.yscale('log')\n",
    "# plt.title(\"rho(r) ground vs rho(r) mcmc comparison\")\n",
    "# plt.xlabel(r'$D_c$')\n",
    "# plt.ylabel('log(rho)')\n",
    "# plt.legend()\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "# sns.histplot(samples['alpha'], stat='density', bins='auto', color='skyblue')\n",
    "# sns.kdeplot(samples['alpha'])\n",
    "# plt.title('Alpha posterior - wider integral, fewer grid points')\n",
    "# plt.show()\n",
    "\n",
    "# sns.histplot(samples['M_star'], stat='density', bins='auto', color='skyblue')\n",
    "# sns.kdeplot(samples['M_star'])\n",
    "# plt.title('M_star posterior - wider integral, fewer grid points')\n",
    "# plt.show()\n",
    "\n",
    "# sns.histplot(samples['psi'], stat='density', bins='auto', color='skyblue')\n",
    "# sns.kdeplot(samples['psi'])\n",
    "# plt.title('Psi posterior - wider integral, fewer grid points')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b69e38",
   "metadata": {},
   "source": [
    "### Reconstruction of $\\rho(r)$ with uncertainty bands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b341d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpyro.diagnostics import hpdi\n",
    "\n",
    "# Posterior samples of the spline control points\n",
    "# shape: (n_samples, n_splines)\n",
    "f_samps = np.array(samples[\"rho_pts\"])\n",
    "\n",
    "# Evaluate rho(r) on r_vals for each posterior sample\n",
    "f_samps_jax = jnp.array(f_samps)  # to JAX\n",
    "r_vals_jax  = jnp.array(r_vals)\n",
    "\n",
    "# vmap over the samples: (n_samples, n_splines) -> (n_samples, n_r)\n",
    "f_vals_samps = vmap(lambda f_pts: f_of_r(r_vals_jax, f_pts))(f_samps_jax)\n",
    "\n",
    "f_vals_samps = f_vals_samps * scaling\n",
    "\n",
    "# Posterior mean and 95% HPDI at each r\n",
    "fmean = jnp.mean(f_vals_samps, axis=0)\n",
    "hpdi_f = hpdi(f_vals_samps, prob=0.95)   # shape (2, n_r)\n",
    "\n",
    "# Convert to numpy for plotting\n",
    "fmean_np   = np.array(fmean)\n",
    "hpdi_f_low = np.array(hpdi_f[0])\n",
    "hpdi_f_hi  = np.array(hpdi_f[1])\n",
    "\n",
    "plt.figure(figsize=(7, 4))\n",
    "plt.plot(r_vals, rho_grid_ground, label='True rho(r)', color='C0', lw=1)\n",
    "plt.plot(r_vals, fmean_np, label='Sampled rho(r) (mean)', color='C1', lw=1)\n",
    "\n",
    "# Uncertainty band\n",
    "plt.fill_between(\n",
    "    r_vals,\n",
    "    hpdi_f_low,\n",
    "    hpdi_f_hi,\n",
    "    color='C1',\n",
    "    alpha=0.3,\n",
    "    interpolate=True,\n",
    "    label='95% HPDI'\n",
    ")\n",
    "\n",
    "plt.yscale('log')\n",
    "plt.title(r\"$\\rho(r)$ ground vs MCMC\")\n",
    "plt.xlabel(r'$D_c$')\n",
    "plt.ylabel(r'$\\rho(r)$')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "## alternative version with ln(rho(r)) plotted with linear axis\n",
    "\n",
    "# Posterior samples of the spline control points\n",
    "# shape: (n_samples, n_splines)\n",
    "f_samps = np.array(samples[\"rho_pts\"])\n",
    "\n",
    "# Convert to JAX\n",
    "f_samps_jax = jnp.array(f_samps)   # (n_samples, n_splines)\n",
    "r_vals_jax  = jnp.array(r_vals)    # (n_r,)\n",
    "\n",
    "# Evaluate rho(r) on r_vals for each posterior sample\n",
    "# f_of_r(r, f_pts) should already be defined and JAX-compatible\n",
    "f_vals_samps = vmap(lambda f_pts: f_of_r(r_vals_jax, f_pts))(f_samps_jax)  # (n_samples, n_r)\n",
    "\n",
    "f_vals_samps = f_vals_samps * scaling\n",
    "\n",
    "# To avoid log(0), add a tiny epsilon\n",
    "eps = 1e-30\n",
    "log_f_vals_samps = jnp.log(f_vals_samps + eps)  # ln rho(r)\n",
    "\n",
    "# Posterior mean and 95% HPDI in log space\n",
    "log_fmean = jnp.mean(log_f_vals_samps, axis=0)         # (n_r,)\n",
    "log_hpdi  = hpdi(log_f_vals_samps, prob=0.95)          # (2, n_r)\n",
    "\n",
    "# Convert to numpy for plotting\n",
    "log_fmean_np   = np.array(log_fmean)\n",
    "log_hpdi_low   = np.array(log_hpdi[0])\n",
    "log_hpdi_high  = np.array(log_hpdi[1])\n",
    "\n",
    "# True profile in log-space\n",
    "log_rho_ground  = np.log(rho_grid_ground + eps)\n",
    "\n",
    "# Plot ln rho(r) vs r\n",
    "plt.figure(figsize=(7, 4))\n",
    "\n",
    "plt.plot(r_vals, log_rho_ground, label='True ln ρ(r)', color='C0', lw=1)\n",
    "plt.plot(r_vals, log_fmean_np, label='Sampled ln ρ(r) (mean)', color='C1', lw=1)\n",
    "\n",
    "plt.fill_between(\n",
    "    r_vals,\n",
    "    log_hpdi_low,\n",
    "    log_hpdi_high,\n",
    "    color='C1',\n",
    "    alpha=0.3,\n",
    "    interpolate=True,\n",
    "    label='95% HPDI (ln ρ)'\n",
    ")\n",
    "\n",
    "plt.title(r\"$\\ln \\rho(r)$ ground vs MCMC\")\n",
    "plt.xlabel(r'$D_c$')\n",
    "plt.ylabel(r'$\\ln \\rho(r)$')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jax_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
